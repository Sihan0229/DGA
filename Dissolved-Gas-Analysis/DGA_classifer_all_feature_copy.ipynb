{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集和测试集文件路径\n",
    "train_path = r'D:\\xjtufiles\\3ee\\DGA\\datasets\\DGA_data_add_cleaned_train.csv'\n",
    "test_path = r'D:\\xjtufiles\\3ee\\DGA\\datasets\\DGA_data_add_cleaned_test.csv'\n",
    "\n",
    "# 预处理训练集\n",
    "df_train = pd.read_csv(train_path)\n",
    "\n",
    "df_train['h2'] = pd.to_numeric(df_train['h2'], errors='coerce')\n",
    "df_train['ch4'] = pd.to_numeric(df_train['ch4'], errors='coerce')\n",
    "df_train['c2h6'] = pd.to_numeric(df_train['c2h6'], errors='coerce')\n",
    "df_train['c2h4'] = pd.to_numeric(df_train['c2h4'], errors='coerce')\n",
    "df_train['c2h2'] = pd.to_numeric(df_train['c2h2'], errors='coerce')\n",
    "df_train['act'] = pd.to_numeric(df_train['act'], errors='coerce')\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)  # 重置索引\n",
    "\n",
    "# 预处理测试集\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "df_test['h2'] = pd.to_numeric(df_test['h2'], errors='coerce')\n",
    "df_test['ch4'] = pd.to_numeric(df_test['ch4'], errors='coerce')\n",
    "df_test['c2h6'] = pd.to_numeric(df_test['c2h6'], errors='coerce')\n",
    "df_test['c2h4'] = pd.to_numeric(df_test['c2h4'], errors='coerce')\n",
    "df_test['c2h2'] = pd.to_numeric(df_test['c2h2'], errors='coerce')\n",
    "df_test['act'] = pd.to_numeric(df_test['act'], errors='coerce')\n",
    "\n",
    "df_test = df_test.reset_index(drop=True)  # 重置索引\n",
    "\n",
    "# 现在，df_train 和 df_test 已经分别完成了预处理\n",
    "print(\"训练集预处理完成，形状：\", df_train.shape)\n",
    "print(\"测试集预处理完成，形状：\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['h2', 'ch4', 'c2h6', 'c2h4', 'c2h2']\n",
    "# 确保特征列为数值类型 (df_train)\n",
    "for col in feature_cols:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# 确保目标列为整数类型 (df_train)\n",
    "df_train['act'] = df_train['act'].astype(int)\n",
    "\n",
    "print(\"训练集数据类型：\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "# 确保特征列为数值类型 (df_test)\n",
    "for col in feature_cols:\n",
    "    df_test[col] = pd.to_numeric(df_test[col], errors='coerce')\n",
    "\n",
    "# 确保目标列为整数类型 (df_test)\n",
    "df_test['act'] = df_test['act'].astype(int)\n",
    "\n",
    "print(\"\\n测试集数据类型：\")\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设 X 是一个 Pandas DataFrame，包含 h2, ch4, c2h6, c2h4, c2h2 列\n",
    "\n",
    "train_all = df_train.copy()\n",
    "test_all = df_test.copy()\n",
    "\n",
    "def all_features(X):\n",
    "    \n",
    "\n",
    "    R1 = X['c2h2'] / (X['c2h2'] + X['ch4'] + X['c2h6'])\n",
    "    # R2= X['ch4'] /  (X['c2h2'] + X['ch4'] + X['c2h6'])\n",
    "    # R3 = X['c2h6'] /  (X['c2h2'] + X['ch4'] + X['c2h6'])\n",
    "    R4 = X['c2h4'] / (X['c2h6'])\n",
    "    R5 = X['c2h2'] / (X['c2h4'])\n",
    "    R6 = X['c2h2'] / (X['h2'] + X['ch4'] + X['c2h2'] + X['c2h4'] + X['c2h6'])\n",
    "    R7 = X['c2h2'] /  (X['ch4'])\n",
    "    R8 = (X['c2h2']+X['ch4']) / (X['h2'] )\n",
    "    # R9 = X['h2'] / (X['c2h2'])\n",
    "    # R10 = X['c2h2'] / (X['c2h4'] + X['ch4'] + X['c2h6'])\n",
    "    # R11 = (X['ch4'] + X['c2h6']) / (X['h2'] + X['ch4'] + X['c2h2'] + X['c2h4'] + X['c2h6'])\n",
    "    # E_H = X['energy_index'] = (X['h2'] * 1 + X['ch4'] * 2 + X['c2h6'] * 3 +  X['c2h4'] * 4 +  X['c2h2'] * 5)\n",
    "    # # E_L = ( X['h2'] * 1 +  X['ch4'] * 2 + X['c2h6'] * 3)\n",
    "    E = (X['h2'] * 1 + X['ch4'] * 2 + X['c2h6'] * 3 +  X['c2h4'] * 4 +  X['c2h2'] * 5)\n",
    "    # 处理异常值\n",
    "    R1 = R1.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    R4 = R4.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    R5 = R5.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    R6 = R6.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    R7 = R7.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    R8 = R8.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    \n",
    "    E = E.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    # 添加到特征矩阵\n",
    "    X['R1: C2H2/(C2H2+CH4+C2H6)'] = R1\n",
    "    X['R4: C2H4/C2H6'] = R4\n",
    "    X['R5: C2H2/C2H4'] = R5\n",
    "    X['R6: C2H2/(H2+CH4+C2H2+C2H4+C2H6)'] = R6\n",
    "    X['R7: C2H2/CH4'] = R7\n",
    "    X['R8: (C2H2+CH4)/H2'] = R8\n",
    "\n",
    "    return X\n",
    "\n",
    "all_train_data = all_features(train_all)\n",
    "all_test_data = all_features(test_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini随机森林 + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, classification_report, confusion_matrix)\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, KMeansSMOTE\n",
    "\n",
    "X_train = all_train_data.drop('act', axis=1)\n",
    "y_train = all_train_data['act']\n",
    "X_test = all_test_data.drop('act', axis=1)\n",
    "y_test = all_test_data['act']\n",
    "\n",
    "# 标签映射（可选）\n",
    "label_mapping = {\n",
    "    1: 'HED',\n",
    "    2: 'HT',\n",
    "    3: 'LED',\n",
    "    4: 'LT',\n",
    "    5: 'MT',\n",
    "    6: 'PD'\n",
    "}\n",
    "target_names = [label_mapping[i] for i in sorted(label_mapping.keys())]\n",
    "\n",
    "# 修改 train_and_evaluate 函数，返回分类报告和 overall metrics\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 每类指标\n",
    "    report_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True, zero_division=0)\n",
    "    \n",
    "    # 转换为DataFrame方便展示\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "    return report_df\n",
    "\n",
    "# 存储结果\n",
    "results = OrderedDict()\n",
    "results['No Oversampling'] = train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 只启用 SMOTE（你可以取消注释其他方法）\n",
    "resamplers = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    # 'ADASYN': ADASYN(random_state=42),\n",
    "    # 'BorderlineSMOTE': BorderlineSMOTE(random_state=42),\n",
    "    # 'KMeansSMOTE': KMeansSMOTE(random_state=42)\n",
    "}\n",
    "\n",
    "for name, sampler in resamplers.items():\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    results[name] = train_and_evaluate(X_resampled, y_resampled, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"\\n=== 每类指标报告 ===\")\n",
    "for method, report_df in results.items():\n",
    "    print(f\"\\n[{method}]\")\n",
    "    print(report_df.loc[target_names][['precision', 'recall', 'f1-score']].round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini随机森林 + SMOTE + SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 应用 SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 训练模型\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 模型预测并评估\n",
    "y_pred = model.predict(X_test)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "for i, class_name in enumerate(model.classes_):\n",
    "    #plt.title(f\"SHAP Summary Plot for Class {class_name}\", fontsize=15)\n",
    "    shap.summary_plot(shap_values[:, :, i], X_test, class_names=[class_name], title=f\"SHAP Summary Plot for Class {class_name}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
